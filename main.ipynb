{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd31283d7664415847dd450014dd9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x03\\x8f\\x00\\x00\\x02\\x04\\x08\\x02\\x00\\x00\\x006\\x0b\\x8c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1879771671ca4ca3a68bc8f290bab503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(FileUpload(value={}, accept='image/*', description='Select an image', layout=Layout(g…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import torch\n",
    "import PIL\n",
    "import io\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "###### Loading classes dictionaries ########\n",
    "with open('imagenet_classes.pkl', 'rb') as f:\n",
    "     imagenet=pickle.load(f)\n",
    "colors=['blue','red','yellow','orange','green','purple','pink','magenta','limegreen','olive','teal','violet','lawngreen']\n",
    "coco_labels=[\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"image_select.png\", \"rb\")#placeholder img\n",
    "image = file.read()\n",
    "\n",
    "###### Initilization of widgets ########\n",
    "\n",
    "uploader=widgets.FileUpload(\n",
    "    accept='image/*',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=False,  # True to accept multiple files upload else False\n",
    "    description='Select an image'\n",
    ")\n",
    "\n",
    "viewer=widgets.Image(value=image)#contains a placeholder image\n",
    "\n",
    "def slider_creation(name): #function to generate sliders\n",
    "    return widgets.FloatSlider(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=2,\n",
    "    step=0.1,\n",
    "    description=name,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    ")\n",
    "\n",
    "sliders=[slider_creation(x) for x in ['Brightness','Color','Contrast']]\n",
    "\n",
    "obj_det=widgets.Button(description=\"Object detection\")\n",
    "\n",
    "img_class=widgets.Button(description=\"Image classification\")\n",
    "\n",
    "semantic_segm=widgets.Button(description=\"Segmentation\")\n",
    "\n",
    "reset=widgets.Button(description=\"Discard changes\")\n",
    "\n",
    "###### Helper functions ########\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "transform = transforms.Compose([#required transformations for various models\n",
    "    transforms.Resize(256),                    \n",
    "    transforms.CenterCrop(224),                \n",
    "    transforms.ToTensor(),                    \n",
    "    transforms.Normalize(                      \n",
    "    mean=[0.485, 0.456, 0.406],                \n",
    "    std=[0.229, 0.224, 0.225]                  \n",
    "     )\n",
    "])\n",
    "\n",
    "def buf2viewer(img): #function thats save the PIL format of image to a virtual buffer and then \n",
    "    #assigns current viewer widget value  to the image in buffer\n",
    "    buf = io.BytesIO()\n",
    "    img.save(buf , format='PNG')\n",
    "    viewer.value=buf.getvalue()\n",
    "\n",
    "def viewer2torch():#converts current viewer image to tensor with the format required to run model()\n",
    "    image = PIL.Image.open(io.BytesIO(viewer.value)).convert('RGB')\n",
    "    image = transforms.functional.to_tensor(image)\n",
    "    return image.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### GUI interaction functions ########\n",
    "def image_open(change):\n",
    "    viewer.value = change.new[list(change.new.keys())[0]]['content']\n",
    "\n",
    "def function_generator(enhance_function): #function to generate function that handles slider changes\n",
    "    #this can't be done with .observe method as it forbids passing arguments to it\n",
    "    def slider_chng(change):\n",
    "            image = PIL.Image.open(io.BytesIO(viewer.value))\n",
    "            enhancer = enhance_function(image)\n",
    "            image=enhancer.enhance(change.new)\n",
    "            buf2viewer(image)\n",
    "    return slider_chng\n",
    "\n",
    "def on_obj_clicked(b):\n",
    "    model =  torch.load('fasterrcnn_mobilenet_v3_large_fpn.pt')\n",
    "    model.eval()\n",
    "    image = PIL.Image.open(io.BytesIO(viewer.value)).convert('RGB')\n",
    "    def add_margin(pil_img, top, right, bottom, left, color):#function that adds padding to the top \n",
    "        #image in case the image is too small to fit the labels source:https://note.nkmk.me/en/python-pillow-add-margin-expand-canvas/\n",
    "        width, height = pil_img.size\n",
    "        new_width = width + right + left\n",
    "        new_height = height + top + bottom\n",
    "        result = PIL.Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "        result.paste(pil_img, (left, top))\n",
    "        return result\n",
    "\n",
    "    if image.size[1]<300:image=add_margin(image, 300-image.size[1], 0, 0, 0, 'white')\n",
    "        \n",
    "    buf2viewer(image)\n",
    "    image_t = viewer2torch()\n",
    "    pred=model(image_t)\n",
    "    scores=pred[0]['scores'].tolist()\n",
    "    keep=[]\n",
    "    for i,score in enumerate(scores):\n",
    "        if score>0.2:keep.append(i)\n",
    "    scores=pred[0]['scores'][keep,].tolist()\n",
    "    labels=[coco_labels[i] for i in pred[0]['labels'][keep,].tolist()]\n",
    "    boxes=pred[0]['boxes'][keep,].tolist()\n",
    "    for index,label in enumerate(labels):\n",
    "        labels[index]=label+': '+str(round(scores[index]*100,1))+'%'\n",
    "    source_img=PIL.Image.open(io.BytesIO(viewer.value)).convert('RGB')\n",
    "    draw = PIL.ImageDraw.Draw(source_img)\n",
    "    for index,box in enumerate(boxes):\n",
    "        color=colors[random.randint(0,len(colors)-1)]\n",
    "        draw.rectangle(box,width=6,outline=color)\n",
    "        draw.text((box[0], box[1]-30), labels[index],font=PIL.ImageFont.truetype(font='calibri.ttf', size=25),fill=color)\n",
    "    buf2viewer(source_img)\n",
    "    \n",
    "def on_reset_clicked(b):\n",
    "    try:\n",
    "        viewer.value=uploader.value[list(uploader.value.keys())[0]]['content']\n",
    "    except IndexError:\n",
    "        viewer.value=image\n",
    "        \n",
    "def on_class_clicked(b):\n",
    "    model=torch.load('mobilenet_v3_large.pt')\n",
    "    model.eval()\n",
    "    image = viewer2torch()\n",
    "    pred=model(image)\n",
    "    _, indices = torch.sort(pred, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(pred, dim=1)[0] * 100\n",
    "    blank=PIL.Image.open('blank.png')\n",
    "    features=[imagenet[idx]+\": \"+ str(round(percentage[idx].item(),1))+\"%\" for idx in indices[0][:5]]\n",
    "    draw = PIL.ImageDraw.Draw(blank)\n",
    "    for idx in range(5):\n",
    "        draw.text((30, 30+(idx*30)), features[idx],font=PIL.ImageFont.truetype(font='calibri.ttf', size=30),fill='black')\n",
    "    blank=blank.crop((0,0,350,200))\n",
    "    image = PIL.Image.open(io.BytesIO(viewer.value)).convert('RGB')\n",
    "    if (image.size[0]<350 or image.size[1]<200):image=image.resize((350,200))# if the image is too small make sure\n",
    "        #that all all information from features list is present on the screen\n",
    "    PIL.Image.Image.paste(image, blank)\n",
    "    buf2viewer(image)\n",
    "\n",
    "def on_segm_clicked(b):\n",
    "    model=torch.load('segm_deeplabv3_mobilenet_v3.pt')\n",
    "    model.eval()\n",
    "    image=viewer2torch()\n",
    "    pred=model(image)\n",
    "    def decode_segmap(image, nc=21):#function copied from https://learnopencv.com/pytorch-for-beginners-semantic-segmentation-using-torchvision/\n",
    "        label_colors = np.array([(0, 0, 0),  # 0=background\n",
    "                   # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "                   (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\n",
    "                   # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "                   (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n",
    "                   # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "                   (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n",
    "                   # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "                   (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n",
    "        r = np.zeros_like(image).astype(np.uint8)\n",
    "        g = np.zeros_like(image).astype(np.uint8)\n",
    "        b = np.zeros_like(image).astype(np.uint8)\n",
    "        for l in range(0, nc):\n",
    "            idx = image == l\n",
    "            r[idx] = label_colors[l, 0]\n",
    "            g[idx] = label_colors[l, 1]\n",
    "            b[idx] = label_colors[l, 2]\n",
    "        rgb = np.stack([r, g, b], axis=2)\n",
    "        return rgb\n",
    "    out=torch.argmax(pred['out'].squeeze(), dim=0).detach().cpu().numpy()\n",
    "    out=torch.from_numpy(decode_segmap(out))\n",
    "    out=out.permute(2,0,1)\n",
    "    to_image=transforms.ToPILImage()\n",
    "    out=to_image(out)\n",
    "    buf2viewer(out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Intiation of GUI ########   \n",
    "  \n",
    "uploader.observe(image_open, names='value')\n",
    "\n",
    "enhancers=[PIL.ImageEnhance.Brightness,PIL.ImageEnhance.Color,PIL.ImageEnhance.Contrast]\n",
    "for idx,slider in enumerate(sliders):\n",
    "    slider.observe(function_generator(enhancers[idx]),names='value')\n",
    "obj_det.on_click(on_obj_clicked)\n",
    "img_class.on_click(on_class_clicked)\n",
    "reset.on_click(on_reset_clicked)\n",
    "semantic_segm.on_click(on_segm_clicked)\n",
    "\n",
    "grid = widgets.GridspecLayout(2, 5)\n",
    "grid[0,0]=uploader\n",
    "grid[0,1]=reset\n",
    "grid[0,2]=obj_det\n",
    "grid[0,3]=img_class\n",
    "grid[0,4]=semantic_segm\n",
    "grid[1,:2]=sliders[0]\n",
    "grid[1,2:4]=sliders[1]\n",
    "grid[1,4]=sliders[2]\n",
    "display(viewer, grid)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c209f5bcd523c12eb07fb8b3529a9631b755109a2439f3b8ef0b7522b509ac81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
